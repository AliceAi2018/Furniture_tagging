{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "IMG_HEIGHT, IMG_WIDTH = 100, 100\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 50\n",
    "VALIDATION_STEPS = 20\n",
    "EPOCHS = 5\n",
    "DATA_PATH  = 'data'\n",
    "# couch_path = os.path.join(DATA_PATH, 'couch')\n",
    "# DATA_PATH = os.path.join(os.getcwd(),'data')\n",
    "# DATA_PATH = os.path.join(os.getcwd(),'data')\n",
    "couch_path = os.path.join(DATA_PATH, 'couch') # 2016 couch pictures, to be augmented \n",
    "chair_path = os.path.join(DATA_PATH, 'chair') # 8141 chair pictures\n",
    "\n",
    "couch_pictures = os.listdir(couch_path)\n",
    "chair_pictures = os.listdir(chair_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    }
   ],
   "source": [
    "# couchaug_path = os.path.join(DATA_PATH, 'couch_aug')\n",
    "# couchaug_pictures=os.listdir(couchaug_path)\n",
    "# print(len(couchaug_pictures))\n",
    "print(len(couch_pictures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(Final_Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator_factory = ImageDataGenerator(\n",
    "#         rotation_range=10, \n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,            \n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# couch_dir = os.path.join(DATA_PATH,'couch_aug')\n",
    "# if not os.path.exists(couch_dir):\n",
    "#     os.mkdir(couch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in couch_pictures:\n",
    "#     img = load_img(os.path.join(couch_path, i), target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    \n",
    "#     img = np.expand_dims(img, axis=0) #必须把第一维补上才能，第一维表示batch size，才能在下一行indicate batch size为1\n",
    "#     img_generator = generator_factory.flow(img, batch_size=1, save_to_dir=couch_dir, save_format='jpg')\n",
    "#     for j in range(3):\n",
    "#         sampled_transformed_img = next(img_generator) # next一次生成一张照片，存在save_to_dir=couch_dir里面\n",
    "#         sampled_transformed_img = np.squeeze(sampled_transformed_img, axis=0) #再把batch所表示的第一维去掉\n",
    "#         #sampled_transformed_img = array_to_img(sampled_transformed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# couchaug_path = os.path.join(DATA_PATH, 'couch_aug')\n",
    "# couchaug_pictures=os.listdir(couchaug_path)\n",
    "# print(len(couchaug_pictures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(couch_pictures))\n",
    "print(len(couch_pictures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-validation split\n",
    "\n",
    "def train_val_split():\n",
    "    couch_train, couch_valtest = train_test_split(couch_pictures, train_size=0.9, test_size=0.1)\n",
    "    chair_train, chair_valtest = train_test_split(chair_pictures, train_size=0.9, test_size=0.1)\n",
    "    couch_val, couch_test = train_test_split(couch_valtest, train_size=0.5, test_size=0.5)\n",
    "    chair_val, chair_test = train_test_split(chair_valtest, train_size=0.5, test_size=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    if not os.path.exists('train'):\n",
    "        os.mkdir('train')\n",
    "        os.mkdir('train/couch')\n",
    "        os.mkdir('train/chair')\n",
    "        for filename in couch_train:\n",
    "            os.rename(os.path.join(couch_path, filename), os.path.join('train/couch', filename))\n",
    "        for filename in chair_train:\n",
    "            os.rename(os.path.join(chair_path, filename), os.path.join('train/chair', filename))\n",
    "\n",
    "    if not os.path.exists('val'):\n",
    "        os.mkdir('val')\n",
    "        os.mkdir('val/couch')\n",
    "        os.mkdir('val/chair')\n",
    "        for filename in couch_val:\n",
    "            os.rename(os.path.join(couch_path, filename), os.path.join('val/couch', filename))\n",
    "        for filename in chair_val:\n",
    "            os.rename(os.path.join(chair_path, filename), os.path.join('val/chair', filename))\n",
    "     \n",
    "    \n",
    "    if not os.path.exists('test'):\n",
    "        os.mkdir('test')\n",
    "        os.mkdir('test/couch')\n",
    "        os.mkdir('test/chair')\n",
    "        for filename in couch_test:\n",
    "            os.rename(os.path.join(couch_path, filename), os.path.join('test/couch', filename))\n",
    "        for filename in chair_test:\n",
    "            os.rename(os.path.join(chair_path, filename), os.path.join('test/chair', filename))\n",
    "            \n",
    "if not os.path.exists('train') and not os.path.exists('test') and not os.path.exists('val'):\n",
    "    train_val_split()\n",
    "    \n",
    "TRAIN_DATA, TEST_DATA = os.path.join(os.getcwd(),'train'), os.path.join(os.getcwd(),'test')\n",
    "VALIDATION_DATA=os.path.join(os.getcwd(),'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/notebooks/tutorials/train'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Data=os.path.join(os.getcwd(),'final_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/notebooks/tutorials/final_test'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9140 images belonging to 2 classes.\n",
      "Found 508 images belonging to 2 classes.\n",
      "Found 509 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# sample augmentations of the couch pictures\n",
    "def setup_generator(data_dir):\n",
    "    generator_factory = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,            \n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            preprocessing_function=preprocess_input)\n",
    "    generator = generator_factory.flow_from_directory(\n",
    "            data_dir, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    return generator\n",
    "\n",
    "train_generator = setup_generator(TRAIN_DATA)\n",
    "val_generator = setup_generator(VALIDATION_DATA)\n",
    "text_generator = setup_generator(TEST_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "Final_Data_generator=setup_generator(Final_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 305,250\n",
      "Trainable params: 305,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.9944 - acc: 0.6794 - val_loss: 0.5776 - val_acc: 0.7516\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.7614 - acc: 0.7837 - val_loss: 0.3280 - val_acc: 0.8648\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.6682 - acc: 0.8095 - val_loss: 0.4703 - val_acc: 0.7862\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.6385 - acc: 0.7913 - val_loss: 0.4538 - val_acc: 0.7358\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5581 - acc: 0.8181 - val_loss: 0.4003 - val_acc: 0.8239\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5976 - acc: 0.8070 - val_loss: 0.3175 - val_acc: 0.8553\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 83s 2s/step - loss: 0.5253 - acc: 0.8319 - val_loss: 0.3025 - val_acc: 0.8365\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5313 - acc: 0.8294 - val_loss: 0.3010 - val_acc: 0.8491\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5249 - acc: 0.8350 - val_loss: 0.2483 - val_acc: 0.8758\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.5064 - acc: 0.8325 - val_loss: 0.3754 - val_acc: 0.8113\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5940 - acc: 0.7900 - val_loss: 0.2828 - val_acc: 0.8648\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4845 - acc: 0.8519 - val_loss: 0.2902 - val_acc: 0.8601\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.5276 - acc: 0.8269 - val_loss: 0.3417 - val_acc: 0.8239\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.5476 - acc: 0.7956 - val_loss: 0.3767 - val_acc: 0.8145\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4772 - acc: 0.8344 - val_loss: 0.2809 - val_acc: 0.8443\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 200s 4s/step - loss: 0.4586 - acc: 0.8462 - val_loss: 0.3016 - val_acc: 0.8443\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.5218 - acc: 0.8181 - val_loss: 0.3880 - val_acc: 0.8035\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.5428 - acc: 0.8169 - val_loss: 0.2887 - val_acc: 0.8491\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4950 - acc: 0.8406 - val_loss: 0.3731 - val_acc: 0.8097\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4395 - acc: 0.8369 - val_loss: 0.2597 - val_acc: 0.8491\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4589 - acc: 0.8319 - val_loss: 0.2957 - val_acc: 0.8270\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.5126 - acc: 0.8219 - val_loss: 0.2784 - val_acc: 0.8616\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4343 - acc: 0.8375 - val_loss: 0.2295 - val_acc: 0.8742\n",
      "Epoch 24/40\n",
      "49/50 [============================>.] - ETA: 1s - loss: 0.4416 - acc: 0.8321"
     ]
    }
   ],
   "source": [
    "# Large images width and heigth\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "def setup_convnet():\n",
    "    \"\"\"Set up a convolutional net for digit classification\"\"\"\n",
    "    img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    conv1 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(img)\n",
    "    conv2 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv2)\n",
    "    img_features = Flatten()(pool1)\n",
    "#     =GlobalAveragePooling2D(pool1)\n",
    "#     dense1 = Dense(64, activation='relu')(img_features)\n",
    "    dense1 = Dense(64, activation='relu',kernel_initializer='lecun_uniform', bias_initializer='lecun_uniform')(img_features)\n",
    "#     dense2=BatchNormalization()(dense1)\n",
    "    dropout2 = Dropout(0.3)(dense1)\n",
    "    classifier = Dense(2, activation='softmax')(dropout2)\n",
    "    model = Model(inputs=img, outputs=classifier)\n",
    "    return model\n",
    "\n",
    "model = setup_convnet()\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_history = model.fit_generator(train_generator, \n",
    "                                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                    epochs=40,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=VALIDATION_STEPS,\n",
    "                                    callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss')],\n",
    "                                    class_weight={0:1,1:4})\n",
    "\n",
    "\n",
    "res2 = model.evaluate_generator(text_generator)\n",
    "res3 = model.evaluate_generator(val_generator)\n",
    "# , steps=72, max_q_size=10, workers=1, pickle_safe=False)\n",
    "print('Result of testing data: ')\n",
    "print(model.metrics_names, '\\n', res2)\n",
    "print('Result of training data: ')\n",
    "print( model.metrics_names, '\\n', res3)\n",
    "\n",
    "predictions = model.predict_generator(text_generator)\n",
    "predictions_val = model.predict_generator(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_val_classes = np.argmax(predictions_val, axis=1)\n",
    "\n",
    "true_classes = text_generator.classes\n",
    "true_val_classes = val_generator.classes\n",
    "class_labels = list(text_generator.class_indices.keys())\n",
    "class_val_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "report_val = classification_report(true_val_classes, predicted_val_classes, target_names=class_val_labels)\n",
    "print(\"Result of testing:\")\n",
    "print (report)\n",
    "print(\"Result of validation: \")\n",
    "print(report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 305,250\n",
      "Trainable params: 305,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 83s 2s/step - loss: 0.9604 - acc: 0.7056 - val_loss: 0.3878 - val_acc: 0.8475\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.6655 - acc: 0.8175 - val_loss: 0.3255 - val_acc: 0.8664\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.6294 - acc: 0.8244 - val_loss: 0.3782 - val_acc: 0.8381\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.6121 - acc: 0.8145 - val_loss: 0.3223 - val_acc: 0.8491\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.5595 - acc: 0.8287 - val_loss: 0.2752 - val_acc: 0.8679\n",
      "Result of testing data: \n",
      "(['loss', 'acc'], '\\n', [0.24540265024528055, 0.88212180664590867])\n",
      "Result of training data: \n",
      "(['loss', 'acc'], '\\n', [0.2575160213342802, 0.87401574897015188])\n",
      "Result of testing:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.79      0.80      0.80       408\n",
      "      couch       0.17      0.16      0.16       101\n",
      "\n",
      "avg / total       0.67      0.68      0.67       509\n",
      "\n",
      "Result of validation: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.81      0.80      0.80       407\n",
      "      couch       0.23      0.24      0.23       101\n",
      "\n",
      "avg / total       0.69      0.69      0.69       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Large images width and heigth\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "def setup_convnet():\n",
    "    \"\"\"Set up a convolutional net for digit classification\"\"\"\n",
    "    img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    conv1 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(img)\n",
    "    conv2 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv2)\n",
    "    img_features = Flatten()(pool1)\n",
    "#     =GlobalAveragePooling2D(pool1)\n",
    "#     dense1 = Dense(64, activation='relu')(img_features)\n",
    "    dense1 = Dense(64, activation='relu',kernel_initializer='lecun_uniform', bias_initializer='lecun_uniform')(img_features)\n",
    "#     dense2=BatchNormalization()(dense1)\n",
    "    dropout2 = Dropout(0.3)(dense1)\n",
    "#     classifier = Dense(2, activation='softmax')(img_features)\n",
    "    classifier = Dense(2, activation='softmax')(dropout2)\n",
    "#     classifier = Dense(2, activation='sigmoid')(dropout2)\n",
    "    model = Model(inputs=img, outputs=classifier)\n",
    "    return model\n",
    "\n",
    "model = setup_convnet()\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_history = model.fit_generator(train_generator, \n",
    "                                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                    epochs=5,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=VALIDATION_STEPS,\n",
    "                                    callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss')],\n",
    "                                    class_weight={0:1,1:4})\n",
    "\n",
    "\n",
    "res2 = model.evaluate_generator(text_generator)\n",
    "res3 = model.evaluate_generator(val_generator)\n",
    "# , steps=72, max_q_size=10, workers=1, pickle_safe=False)\n",
    "print('Result of testing data: ')\n",
    "print(model.metrics_names, '\\n', res2)\n",
    "print('Result of training data: ')\n",
    "print( model.metrics_names, '\\n', res3)\n",
    "\n",
    "predictions = model.predict_generator(text_generator)\n",
    "predictions_val = model.predict_generator(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_val_classes = np.argmax(predictions_val, axis=1)\n",
    "\n",
    "true_classes = text_generator.classes\n",
    "true_val_classes = val_generator.classes\n",
    "class_labels = list(text_generator.class_indices.keys())\n",
    "class_val_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "report_val = classification_report(true_val_classes, predicted_val_classes, target_names=class_val_labels)\n",
    "print(\"Result of testing:\")\n",
    "print (report)\n",
    "print(\"Result of validation: \")\n",
    "print(report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINED_WEIGHTS_FILENAME = 'model1.hdf5'\n",
    "model.save(TRAINED_WEIGHTS_FILENAME)\n",
    "model = load_model(TRAINED_WEIGHTS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f5cbf3f8490>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "data_generator = datagen.flow_from_directory(\n",
    "            Final_Data,\n",
    "            target_size=(100, 100),\n",
    "            batch_size=batch_size,\n",
    "            shuffle = False, # Important !!!\n",
    "            seed = 59,\n",
    "            classes = None,\n",
    "            class_mode = None)\n",
    "image_list = data_generator.filenames\n",
    "image_list = [x.split('/')[1].split('.')[0] for x in image_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 305,250\n",
      "Trainable params: 305,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 82s 2s/step - loss: 1.0261 - acc: 0.7069 - val_loss: 0.6201 - val_acc: 0.6965\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.7135 - acc: 0.7994 - val_loss: 0.3709 - val_acc: 0.8318\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.6431 - acc: 0.8109 - val_loss: 0.3778 - val_acc: 0.8302\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 81s 2s/step - loss: 0.5522 - acc: 0.8444 - val_loss: 0.4220 - val_acc: 0.7862\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.5266 - acc: 0.8319 - val_loss: 0.2551 - val_acc: 0.8758\n",
      "Result of testing data: \n",
      "(['loss', 'acc'], '\\n', [0.27858302178692024, 0.86247544040380153])\n",
      "Result of training data: \n",
      "(['loss', 'acc'], '\\n', [0.26598868407602383, 0.88188976424885546])\n",
      "Result of testing:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.80      0.77      0.78       408\n",
      "      couch       0.18      0.21      0.19       101\n",
      "\n",
      "avg / total       0.67      0.66      0.66       509\n",
      "\n",
      "Result of validation: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.81      0.77      0.79       407\n",
      "      couch       0.22      0.26      0.24       101\n",
      "\n",
      "avg / total       0.69      0.67      0.68       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def setup_convnet():\n",
    "    \"\"\"Set up a convolutional net for digit classification\"\"\"\n",
    "    img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    conv1 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(img)\n",
    "    conv2 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv2)\n",
    "    #dropout1 = Dropout(0.25)(pool1)\n",
    "#     conv3 = Conv2D(64, kernel_size=(30, 30), strides=1, activation='relu')(pool1)\n",
    "#     conv4 = Conv2D(64, kernel_size=(30, 30), strides=1, activation='relu')(conv3)\n",
    "# #     pool2 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv4)\n",
    "    img_features = Flatten()(pool1)\n",
    "#     =GlobalAveragePooling2D(pool1)\n",
    "#     dense1 = Dense(64, activation='relu')(img_features)\n",
    "    dense1 = Dense(64, activation='relu')(img_features)\n",
    "    dropout2 = Dropout(0.3)(dense1)\n",
    "#     classifier = Dense(2, activation='softmax')(img_features)\n",
    "#     classifier = Dense(2, activation='softmax')(dropout2)\n",
    "    classifier = Dense(2, activation='softmax')(dropout2)\n",
    "    model = Model(inputs=img, outputs=classifier)\n",
    "    return model\n",
    "\n",
    "model = setup_convnet()\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_history = model.fit_generator(train_generator, \n",
    "                                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=VALIDATION_STEPS,\n",
    "                                    callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss')],\n",
    "                                    class_weight={0:1,1:4})\n",
    "\n",
    "\n",
    "res2 = model.evaluate_generator(text_generator)\n",
    "res3 = model.evaluate_generator(val_generator)\n",
    "# , steps=72, max_q_size=10, workers=1, pickle_safe=False)\n",
    "print('Result of testing data: ')\n",
    "print(model.metrics_names, '\\n', res2)\n",
    "print('Result of training data: ')\n",
    "print( model.metrics_names, '\\n', res3)\n",
    "\n",
    "predictions = model.predict_generator(text_generator)\n",
    "predictions_val = model.predict_generator(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_val_classes = np.argmax(predictions_val, axis=1)\n",
    "\n",
    "true_classes = text_generator.classes\n",
    "true_val_classes = val_generator.classes\n",
    "class_labels = list(text_generator.class_indices.keys())\n",
    "class_val_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "report_val = classification_report(true_val_classes, predicted_val_classes, target_names=class_val_labels)\n",
    "print(\"Result of testing:\")\n",
    "print (report)\n",
    "print(\"Result of validation: \")\n",
    "print(report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 9218      \n",
      "=================================================================\n",
      "Total params: 19,362\n",
      "Trainable params: 19,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.0203 - acc: 0.7075 - val_loss: 0.6015 - val_acc: 0.6934\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 193s 4s/step - loss: 0.7333 - acc: 0.8100 - val_loss: 0.3727 - val_acc: 0.8569\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1051s 21s/step - loss: 0.6636 - acc: 0.8237 - val_loss: 0.4994 - val_acc: 0.7720\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.7024 - acc: 0.8000 - val_loss: 0.4326 - val_acc: 0.8145\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.6049 - acc: 0.8189 - val_loss: 0.3211 - val_acc: 0.8506\n",
      "Result of testing data: \n",
      "(['loss', 'acc'], '\\n', [0.32530861103464437, 0.86247544122351172])\n",
      "Result of training data: \n",
      "(['loss', 'acc'], '\\n', [0.32256349123369049, 0.8641732278771288])\n",
      "Result of testing:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.80      0.73      0.76       408\n",
      "      couch       0.20      0.28      0.23       101\n",
      "\n",
      "avg / total       0.68      0.64      0.66       509\n",
      "\n",
      "Result of validation: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      chair       0.81      0.76      0.78       407\n",
      "      couch       0.22      0.28      0.25       101\n",
      "\n",
      "avg / total       0.69      0.66      0.68       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def setup_convnet():\n",
    "    \"\"\"Set up a convolutional net for digit classification\"\"\"\n",
    "    img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    conv1 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(img)\n",
    "    conv2 = Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv2)\n",
    "    #dropout1 = Dropout(0.25)(pool1)\n",
    "#     conv3 = Conv2D(64, kernel_size=(30, 30), strides=1, activation='relu')(pool1)\n",
    "#     conv4 = Conv2D(64, kernel_size=(30, 30), strides=1, activation='relu')(conv3)\n",
    "# #     pool2 = MaxPooling2D(pool_size=(8, 8), strides=(8, 8))(conv4)\n",
    "    img_features = Flatten()(pool1)\n",
    "#     =GlobalAveragePooling2D(pool1)\n",
    "#     dense1 = Dense(64, activation='relu')(img_features)\n",
    "#     dense1 = Dense(64, activation='relu')(dense1)\n",
    "#     dropout2 = Dropout(0.1)(dense1)\n",
    "#     classifier = Dense(2, activation='softmax')(img_features)\n",
    "#     classifier = Dense(2, activation='softmax')(dropout2)\n",
    "    classifier = Dense(2, activation='softmax')(img_features)\n",
    "    model = Model(inputs=img, outputs=classifier)\n",
    "    return model\n",
    "\n",
    "model = setup_convnet()\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_history = model.fit_generator(train_generator, \n",
    "                                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=VALIDATION_STEPS,class_weight={0:1,1:5})\n",
    "\n",
    "\n",
    "res2 = model.evaluate_generator(text_generator)\n",
    "res3 = model.evaluate_generator(val_generator)\n",
    "# , steps=72, max_q_size=10, workers=1, pickle_safe=False)\n",
    "print('Result of testing data: ')\n",
    "print(model.metrics_names, '\\n', res2)\n",
    "print('Result of training data: ')\n",
    "print( model.metrics_names, '\\n', res3)\n",
    "\n",
    "predictions = model.predict_generator(text_generator)\n",
    "predictions_val = model.predict_generator(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_val_classes = np.argmax(predictions_val, axis=1)\n",
    "\n",
    "true_classes = text_generator.classes\n",
    "true_val_classes = val_generator.classes\n",
    "class_labels = list(text_generator.class_indices.keys())\n",
    "class_val_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "report_val = classification_report(true_val_classes, predicted_val_classes, target_names=class_val_labels)\n",
    "print(\"Result of testing:\")\n",
    "print (report)\n",
    "print(\"Result of validation: \")\n",
    "print(report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINED_WEIGHTS_FILENAME = 'model_weights.hdf5'\n",
    "model.save(TRAINED_WEIGHTS_FILENAME)\n",
    "model = load_model(TRAINED_WEIGHTS_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
